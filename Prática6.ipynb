{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BCC325_Prática6.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "81cTAWBhopZM",
        "outputId": "b0339426-f7ab-4a91-d888-c41df50d578c"
      },
      "source": [
        "'''\n",
        "\n",
        "Universidade Federal de Ouro Preto\n",
        "Atividade BCC325 – Semanas 11 e 12\n",
        "\n",
        "Nome: Mariana Regina Ferreira Mota\n",
        "Número de matrícula: 17.2.1332\n",
        "\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n\\nUniversidade Federal de Ouro Preto\\nAtividade BCC325 – Semanas 11 e 12\\n\\nNome: Mariana Regina Ferreira Mota\\nNúmero de matrícula: 17.2.1332\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drun50amZjrZ"
      },
      "source": [
        "import keras as K\n",
        "from keras.utils import to_categorical\n",
        "import numpy as np\n",
        "\n",
        "# Loads dataset\n",
        "train, test = K.datasets.cifar10.load_data()\n",
        "\n",
        "x_train, y_train = train\n",
        "x_test, y_test = test\n",
        "\n",
        "x_train = x_train/255\n",
        "x_test = x_test/255\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLsfk-qmahoO"
      },
      "source": [
        "from keras.layers import Input, Flatten, Dense, ReLU, Softmax, Dropout\n",
        "from keras import Model\n",
        "\n",
        "# Define model\n",
        "\n",
        "input = Input(shape=x_train.shape[1:])\n",
        "\n",
        "x = Flatten()(input)\n",
        "x = Dense(units=512)(x)\n",
        "x = ReLU()(x)\n",
        "x = Dropout(0.2)(x)\n",
        "x = Dense(units=512)(x)\n",
        "x = ReLU()(x)\n",
        "x = Dense(units=256)(x)\n",
        "x = ReLU()(x)\n",
        "x = Dense(units=256)(x)\n",
        "x = ReLU()(x)\n",
        "x = Dropout(0.2)(x)\n",
        "x = Dense(units=128)(x)\n",
        "x = ReLU()(x)\n",
        "x = Dense(units=10)(x)\n",
        "output = Softmax()(x)\n",
        "\n",
        "model = Model(input, output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14ely29Iauu-"
      },
      "source": [
        "from keras.optimizers import SGD\n",
        "\n",
        "# Defines backpropagation parameters\n",
        "\n",
        "opt = SGD(momentum=0.9)\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCiuvTSq7qMR"
      },
      "source": [
        " from keras.callbacks import ReduceLROnPlateau, LearningRateScheduler\n",
        "\n",
        " def scheduler(epoch):\n",
        "        lrs = [0.1] * 20 + [0.01] * 30 + [0.0001] * 40\n",
        "        return lrs[epoch]\n",
        "\n",
        " callback = LearningRateScheduler(scheduler, verbose=1)\n",
        "#[ReduceLROnPlateau(factor=0.1, patience=3,verbose=1)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRuhX0tvbKCR",
        "outputId": "3997a50a-1d32-46a1-ada9-d3b4e6ae09ff"
      },
      "source": [
        "#Train model\n",
        "\n",
        "model.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    batch_size=64,\n",
        "    epochs=30,\n",
        "    verbose=1,\n",
        "    callbacks=[callback],\n",
        "    validation_split=0.1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/90\n",
            "\n",
            "Epoch 00001: LearningRateScheduler reducing learning rate to 0.01.\n",
            "704/704 [==============================] - 31s 43ms/step - loss: 1.9080 - accuracy: 0.3126 - val_loss: 1.5892 - val_accuracy: 0.4456\n",
            "Epoch 2/90\n",
            "\n",
            "Epoch 00002: LearningRateScheduler reducing learning rate to 0.01.\n",
            "704/704 [==============================] - 29s 42ms/step - loss: 1.5936 - accuracy: 0.4356 - val_loss: 1.5482 - val_accuracy: 0.4524\n",
            "Epoch 3/90\n",
            "\n",
            "Epoch 00003: LearningRateScheduler reducing learning rate to 0.01.\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 1.4700 - accuracy: 0.4781 - val_loss: 1.4232 - val_accuracy: 0.4986\n",
            "Epoch 4/90\n",
            "\n",
            "Epoch 00004: LearningRateScheduler reducing learning rate to 0.01.\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 1.3828 - accuracy: 0.5106 - val_loss: 1.3895 - val_accuracy: 0.5072\n",
            "Epoch 5/90\n",
            "\n",
            "Epoch 00005: LearningRateScheduler reducing learning rate to 0.01.\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 1.3214 - accuracy: 0.5280 - val_loss: 1.3691 - val_accuracy: 0.5104\n",
            "Epoch 6/90\n",
            "\n",
            "Epoch 00006: LearningRateScheduler reducing learning rate to 0.01.\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 1.2635 - accuracy: 0.5531 - val_loss: 1.3267 - val_accuracy: 0.5280\n",
            "Epoch 7/90\n",
            "\n",
            "Epoch 00007: LearningRateScheduler reducing learning rate to 0.01.\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 1.2146 - accuracy: 0.5666 - val_loss: 1.3194 - val_accuracy: 0.5292\n",
            "Epoch 8/90\n",
            "\n",
            "Epoch 00008: LearningRateScheduler reducing learning rate to 0.01.\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 1.1766 - accuracy: 0.5853 - val_loss: 1.3026 - val_accuracy: 0.5436\n",
            "Epoch 9/90\n",
            "\n",
            "Epoch 00009: LearningRateScheduler reducing learning rate to 0.01.\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 1.1320 - accuracy: 0.5976 - val_loss: 1.3127 - val_accuracy: 0.5426\n",
            "Epoch 10/90\n",
            "\n",
            "Epoch 00010: LearningRateScheduler reducing learning rate to 0.01.\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 1.0923 - accuracy: 0.6120 - val_loss: 1.3249 - val_accuracy: 0.5380\n",
            "Epoch 11/90\n",
            "\n",
            "Epoch 00011: LearningRateScheduler reducing learning rate to 0.01.\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 1.0469 - accuracy: 0.6250 - val_loss: 1.3363 - val_accuracy: 0.5342\n",
            "Epoch 12/90\n",
            "\n",
            "Epoch 00012: LearningRateScheduler reducing learning rate to 0.01.\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 1.0167 - accuracy: 0.6364 - val_loss: 1.3083 - val_accuracy: 0.5570\n",
            "Epoch 13/90\n",
            "\n",
            "Epoch 00013: LearningRateScheduler reducing learning rate to 0.01.\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.9764 - accuracy: 0.6502 - val_loss: 1.3152 - val_accuracy: 0.5468\n",
            "Epoch 14/90\n",
            "\n",
            "Epoch 00014: LearningRateScheduler reducing learning rate to 0.01.\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.9377 - accuracy: 0.6668 - val_loss: 1.3273 - val_accuracy: 0.5482\n",
            "Epoch 15/90\n",
            "\n",
            "Epoch 00015: LearningRateScheduler reducing learning rate to 0.01.\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.9163 - accuracy: 0.6709 - val_loss: 1.3406 - val_accuracy: 0.5502\n",
            "Epoch 16/90\n",
            "\n",
            "Epoch 00016: LearningRateScheduler reducing learning rate to 0.01.\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.8785 - accuracy: 0.6904 - val_loss: 1.3633 - val_accuracy: 0.5512\n",
            "Epoch 17/90\n",
            "\n",
            "Epoch 00017: LearningRateScheduler reducing learning rate to 0.01.\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.8397 - accuracy: 0.6979 - val_loss: 1.3386 - val_accuracy: 0.5620\n",
            "Epoch 18/90\n",
            "\n",
            "Epoch 00018: LearningRateScheduler reducing learning rate to 0.01.\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.8135 - accuracy: 0.7116 - val_loss: 1.3554 - val_accuracy: 0.5542\n",
            "Epoch 19/90\n",
            "\n",
            "Epoch 00019: LearningRateScheduler reducing learning rate to 0.01.\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.7812 - accuracy: 0.7188 - val_loss: 1.3882 - val_accuracy: 0.5520\n",
            "Epoch 20/90\n",
            "\n",
            "Epoch 00020: LearningRateScheduler reducing learning rate to 0.01.\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.7709 - accuracy: 0.7248 - val_loss: 1.4086 - val_accuracy: 0.5464\n",
            "Epoch 21/90\n",
            "\n",
            "Epoch 00021: LearningRateScheduler reducing learning rate to 0.001.\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.7235 - accuracy: 0.7445 - val_loss: 1.4040 - val_accuracy: 0.5670\n",
            "Epoch 22/90\n",
            "\n",
            "Epoch 00022: LearningRateScheduler reducing learning rate to 0.001.\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.5327 - accuracy: 0.8111 - val_loss: 1.4504 - val_accuracy: 0.5692\n",
            "Epoch 23/90\n",
            "\n",
            "Epoch 00023: LearningRateScheduler reducing learning rate to 0.001.\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.4833 - accuracy: 0.8243 - val_loss: 1.4907 - val_accuracy: 0.5752\n",
            "Epoch 24/90\n",
            "\n",
            "Epoch 00024: LearningRateScheduler reducing learning rate to 0.001.\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.4632 - accuracy: 0.8339 - val_loss: 1.5258 - val_accuracy: 0.5740\n",
            "Epoch 25/90\n",
            "\n",
            "Epoch 00025: LearningRateScheduler reducing learning rate to 0.001.\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.4516 - accuracy: 0.8377 - val_loss: 1.5609 - val_accuracy: 0.5782\n",
            "Epoch 26/90\n",
            "\n",
            "Epoch 00026: LearningRateScheduler reducing learning rate to 0.001.\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.4226 - accuracy: 0.8474 - val_loss: 1.5635 - val_accuracy: 0.5712\n",
            "Epoch 27/90\n",
            "\n",
            "Epoch 00027: LearningRateScheduler reducing learning rate to 0.001.\n",
            "704/704 [==============================] - 31s 44ms/step - loss: 0.4233 - accuracy: 0.8481 - val_loss: 1.6028 - val_accuracy: 0.5752\n",
            "Epoch 28/90\n",
            "\n",
            "Epoch 00028: LearningRateScheduler reducing learning rate to 0.001.\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.4032 - accuracy: 0.8542 - val_loss: 1.6263 - val_accuracy: 0.5746\n",
            "Epoch 29/90\n",
            "\n",
            "Epoch 00029: LearningRateScheduler reducing learning rate to 0.001.\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.3950 - accuracy: 0.8583 - val_loss: 1.6404 - val_accuracy: 0.5670\n",
            "Epoch 30/90\n",
            "\n",
            "Epoch 00030: LearningRateScheduler reducing learning rate to 0.001.\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.3775 - accuracy: 0.8633 - val_loss: 1.6591 - val_accuracy: 0.5712\n",
            "Epoch 31/90\n",
            "\n",
            "Epoch 00031: LearningRateScheduler reducing learning rate to 0.001.\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.3665 - accuracy: 0.8662 - val_loss: 1.6905 - val_accuracy: 0.5710\n",
            "Epoch 32/90\n",
            "\n",
            "Epoch 00032: LearningRateScheduler reducing learning rate to 0.001.\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.3535 - accuracy: 0.8732 - val_loss: 1.6961 - val_accuracy: 0.5734\n",
            "Epoch 33/90\n",
            "\n",
            "Epoch 00033: LearningRateScheduler reducing learning rate to 0.001.\n",
            "704/704 [==============================] - 29s 42ms/step - loss: 0.3537 - accuracy: 0.8702 - val_loss: 1.7350 - val_accuracy: 0.5714\n",
            "Epoch 34/90\n",
            "\n",
            "Epoch 00034: LearningRateScheduler reducing learning rate to 0.001.\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.3461 - accuracy: 0.8766 - val_loss: 1.7287 - val_accuracy: 0.5720\n",
            "Epoch 35/90\n",
            "\n",
            "Epoch 00035: LearningRateScheduler reducing learning rate to 0.001.\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.3375 - accuracy: 0.8785 - val_loss: 1.7614 - val_accuracy: 0.5706\n",
            "Epoch 36/90\n",
            "\n",
            "Epoch 00036: LearningRateScheduler reducing learning rate to 0.001.\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.3255 - accuracy: 0.8834 - val_loss: 1.7916 - val_accuracy: 0.5666\n",
            "Epoch 37/90\n",
            "\n",
            "Epoch 00037: LearningRateScheduler reducing learning rate to 0.001.\n",
            "704/704 [==============================] - 29s 42ms/step - loss: 0.3210 - accuracy: 0.8832 - val_loss: 1.8083 - val_accuracy: 0.5726\n",
            "Epoch 38/90\n",
            "\n",
            "Epoch 00038: LearningRateScheduler reducing learning rate to 0.001.\n",
            "704/704 [==============================] - 29s 42ms/step - loss: 0.3038 - accuracy: 0.8918 - val_loss: 1.8240 - val_accuracy: 0.5696\n",
            "Epoch 39/90\n",
            "\n",
            "Epoch 00039: LearningRateScheduler reducing learning rate to 0.001.\n",
            "704/704 [==============================] - 29s 42ms/step - loss: 0.3063 - accuracy: 0.8920 - val_loss: 1.8474 - val_accuracy: 0.5700\n",
            "Epoch 40/90\n",
            "\n",
            "Epoch 00040: LearningRateScheduler reducing learning rate to 0.001.\n",
            "704/704 [==============================] - 29s 42ms/step - loss: 0.3033 - accuracy: 0.8907 - val_loss: 1.8663 - val_accuracy: 0.5706\n",
            "Epoch 41/90\n",
            "\n",
            "Epoch 00041: LearningRateScheduler reducing learning rate to 0.001.\n",
            "704/704 [==============================] - 29s 42ms/step - loss: 0.2922 - accuracy: 0.8951 - val_loss: 1.8976 - val_accuracy: 0.5690\n",
            "Epoch 42/90\n",
            "\n",
            "Epoch 00042: LearningRateScheduler reducing learning rate to 0.001.\n",
            "704/704 [==============================] - 29s 42ms/step - loss: 0.2902 - accuracy: 0.8971 - val_loss: 1.9242 - val_accuracy: 0.5700\n",
            "Epoch 43/90\n",
            "\n",
            "Epoch 00043: LearningRateScheduler reducing learning rate to 0.001.\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.2707 - accuracy: 0.9033 - val_loss: 1.9407 - val_accuracy: 0.5684\n",
            "Epoch 44/90\n",
            "\n",
            "Epoch 00044: LearningRateScheduler reducing learning rate to 0.001.\n",
            "704/704 [==============================] - 29s 42ms/step - loss: 0.2712 - accuracy: 0.9040 - val_loss: 1.9335 - val_accuracy: 0.5690\n",
            "Epoch 45/90\n",
            "\n",
            "Epoch 00045: LearningRateScheduler reducing learning rate to 0.001.\n",
            "704/704 [==============================] - 29s 42ms/step - loss: 0.2618 - accuracy: 0.9070 - val_loss: 1.9588 - val_accuracy: 0.5692\n",
            "Epoch 46/90\n",
            "\n",
            "Epoch 00046: LearningRateScheduler reducing learning rate to 0.001.\n",
            "704/704 [==============================] - 29s 42ms/step - loss: 0.2647 - accuracy: 0.9070 - val_loss: 1.9487 - val_accuracy: 0.5710\n",
            "Epoch 47/90\n",
            "\n",
            "Epoch 00047: LearningRateScheduler reducing learning rate to 0.001.\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.2571 - accuracy: 0.9094 - val_loss: 1.9659 - val_accuracy: 0.5704\n",
            "Epoch 48/90\n",
            "\n",
            "Epoch 00048: LearningRateScheduler reducing learning rate to 0.001.\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.2513 - accuracy: 0.9111 - val_loss: 2.0063 - val_accuracy: 0.5692\n",
            "Epoch 49/90\n",
            "\n",
            "Epoch 00049: LearningRateScheduler reducing learning rate to 0.001.\n",
            "704/704 [==============================] - 31s 43ms/step - loss: 0.2478 - accuracy: 0.9134 - val_loss: 2.0324 - val_accuracy: 0.5710\n",
            "Epoch 50/90\n",
            "\n",
            "Epoch 00050: LearningRateScheduler reducing learning rate to 0.001.\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.2474 - accuracy: 0.9123 - val_loss: 1.9887 - val_accuracy: 0.5670\n",
            "Epoch 51/90\n",
            "\n",
            "Epoch 00051: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.2415 - accuracy: 0.9156 - val_loss: 2.0002 - val_accuracy: 0.5644\n",
            "Epoch 52/90\n",
            "\n",
            "Epoch 00052: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.2275 - accuracy: 0.9210 - val_loss: 1.9975 - val_accuracy: 0.5660\n",
            "Epoch 53/90\n",
            "\n",
            "Epoch 00053: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.2284 - accuracy: 0.9206 - val_loss: 1.9979 - val_accuracy: 0.5664\n",
            "Epoch 54/90\n",
            "\n",
            "Epoch 00054: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.2232 - accuracy: 0.9209 - val_loss: 1.9984 - val_accuracy: 0.5670\n",
            "Epoch 55/90\n",
            "\n",
            "Epoch 00055: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "704/704 [==============================] - 31s 44ms/step - loss: 0.2188 - accuracy: 0.9240 - val_loss: 1.9980 - val_accuracy: 0.5668\n",
            "Epoch 56/90\n",
            "\n",
            "Epoch 00056: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "704/704 [==============================] - 31s 44ms/step - loss: 0.2314 - accuracy: 0.9168 - val_loss: 1.9994 - val_accuracy: 0.5678\n",
            "Epoch 57/90\n",
            "\n",
            "Epoch 00057: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "704/704 [==============================] - 37s 53ms/step - loss: 0.2235 - accuracy: 0.9222 - val_loss: 1.9995 - val_accuracy: 0.5668\n",
            "Epoch 58/90\n",
            "\n",
            "Epoch 00058: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "704/704 [==============================] - 35s 50ms/step - loss: 0.2261 - accuracy: 0.9214 - val_loss: 2.0052 - val_accuracy: 0.5674\n",
            "Epoch 59/90\n",
            "\n",
            "Epoch 00059: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "704/704 [==============================] - 34s 49ms/step - loss: 0.2128 - accuracy: 0.9276 - val_loss: 2.0008 - val_accuracy: 0.5694\n",
            "Epoch 60/90\n",
            "\n",
            "Epoch 00060: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "704/704 [==============================] - 36s 51ms/step - loss: 0.2231 - accuracy: 0.9232 - val_loss: 2.0034 - val_accuracy: 0.5688\n",
            "Epoch 61/90\n",
            "\n",
            "Epoch 00061: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "704/704 [==============================] - 31s 44ms/step - loss: 0.2179 - accuracy: 0.9228 - val_loss: 2.0066 - val_accuracy: 0.5690\n",
            "Epoch 62/90\n",
            "\n",
            "Epoch 00062: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "704/704 [==============================] - 37s 52ms/step - loss: 0.2133 - accuracy: 0.9260 - val_loss: 2.0054 - val_accuracy: 0.5682\n",
            "Epoch 63/90\n",
            "\n",
            "Epoch 00063: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "704/704 [==============================] - 39s 55ms/step - loss: 0.2172 - accuracy: 0.9246 - val_loss: 2.0062 - val_accuracy: 0.5686\n",
            "Epoch 64/90\n",
            "\n",
            "Epoch 00064: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.2200 - accuracy: 0.9233 - val_loss: 2.0118 - val_accuracy: 0.5694\n",
            "Epoch 65/90\n",
            "\n",
            "Epoch 00065: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.2119 - accuracy: 0.9261 - val_loss: 2.0121 - val_accuracy: 0.5686\n",
            "Epoch 66/90\n",
            "\n",
            "Epoch 00066: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.2167 - accuracy: 0.9254 - val_loss: 2.0072 - val_accuracy: 0.5676\n",
            "Epoch 67/90\n",
            "\n",
            "Epoch 00067: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.2121 - accuracy: 0.9271 - val_loss: 2.0163 - val_accuracy: 0.5692\n",
            "Epoch 68/90\n",
            "\n",
            "Epoch 00068: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.2148 - accuracy: 0.9250 - val_loss: 2.0152 - val_accuracy: 0.5680\n",
            "Epoch 69/90\n",
            "\n",
            "Epoch 00069: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "704/704 [==============================] - 29s 42ms/step - loss: 0.2078 - accuracy: 0.9287 - val_loss: 2.0155 - val_accuracy: 0.5686\n",
            "Epoch 70/90\n",
            "\n",
            "Epoch 00070: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.2135 - accuracy: 0.9244 - val_loss: 2.0156 - val_accuracy: 0.5684\n",
            "Epoch 71/90\n",
            "\n",
            "Epoch 00071: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.2160 - accuracy: 0.9249 - val_loss: 2.0195 - val_accuracy: 0.5684\n",
            "Epoch 72/90\n",
            "\n",
            "Epoch 00072: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.2044 - accuracy: 0.9288 - val_loss: 2.0178 - val_accuracy: 0.5684\n",
            "Epoch 73/90\n",
            "\n",
            "Epoch 00073: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.2074 - accuracy: 0.9284 - val_loss: 2.0191 - val_accuracy: 0.5682\n",
            "Epoch 74/90\n",
            "\n",
            "Epoch 00074: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.2106 - accuracy: 0.9280 - val_loss: 2.0211 - val_accuracy: 0.5688\n",
            "Epoch 75/90\n",
            "\n",
            "Epoch 00075: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.2104 - accuracy: 0.9256 - val_loss: 2.0238 - val_accuracy: 0.5686\n",
            "Epoch 76/90\n",
            "\n",
            "Epoch 00076: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.2070 - accuracy: 0.9259 - val_loss: 2.0279 - val_accuracy: 0.5686\n",
            "Epoch 77/90\n",
            "\n",
            "Epoch 00077: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.2088 - accuracy: 0.9280 - val_loss: 2.0275 - val_accuracy: 0.5688\n",
            "Epoch 78/90\n",
            "\n",
            "Epoch 00078: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "704/704 [==============================] - 41s 58ms/step - loss: 0.2115 - accuracy: 0.9264 - val_loss: 2.0250 - val_accuracy: 0.5678\n",
            "Epoch 79/90\n",
            "\n",
            "Epoch 00079: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "704/704 [==============================] - 55s 78ms/step - loss: 0.2175 - accuracy: 0.9225 - val_loss: 2.0301 - val_accuracy: 0.5666\n",
            "Epoch 80/90\n",
            "\n",
            "Epoch 00080: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "704/704 [==============================] - 59s 83ms/step - loss: 0.2085 - accuracy: 0.9263 - val_loss: 2.0300 - val_accuracy: 0.5682\n",
            "Epoch 81/90\n",
            "\n",
            "Epoch 00081: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "704/704 [==============================] - 48s 68ms/step - loss: 0.2044 - accuracy: 0.9289 - val_loss: 2.0311 - val_accuracy: 0.5680\n",
            "Epoch 82/90\n",
            "\n",
            "Epoch 00082: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "704/704 [==============================] - 49s 69ms/step - loss: 0.2110 - accuracy: 0.9256 - val_loss: 2.0290 - val_accuracy: 0.5678\n",
            "Epoch 83/90\n",
            "\n",
            "Epoch 00083: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "704/704 [==============================] - 52s 73ms/step - loss: 0.2054 - accuracy: 0.9285 - val_loss: 2.0336 - val_accuracy: 0.5682\n",
            "Epoch 84/90\n",
            "\n",
            "Epoch 00084: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "704/704 [==============================] - 49s 69ms/step - loss: 0.2028 - accuracy: 0.9300 - val_loss: 2.0340 - val_accuracy: 0.5682\n",
            "Epoch 85/90\n",
            "\n",
            "Epoch 00085: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "704/704 [==============================] - 48s 68ms/step - loss: 0.2027 - accuracy: 0.9294 - val_loss: 2.0355 - val_accuracy: 0.5688\n",
            "Epoch 86/90\n",
            "\n",
            "Epoch 00086: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "704/704 [==============================] - 52s 74ms/step - loss: 0.2099 - accuracy: 0.9266 - val_loss: 2.0386 - val_accuracy: 0.5688\n",
            "Epoch 87/90\n",
            "\n",
            "Epoch 00087: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "704/704 [==============================] - 53s 75ms/step - loss: 0.2066 - accuracy: 0.9286 - val_loss: 2.0357 - val_accuracy: 0.5688\n",
            "Epoch 88/90\n",
            "\n",
            "Epoch 00088: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "704/704 [==============================] - 56s 79ms/step - loss: 0.2087 - accuracy: 0.9266 - val_loss: 2.0390 - val_accuracy: 0.5692\n",
            "Epoch 89/90\n",
            "\n",
            "Epoch 00089: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "704/704 [==============================] - 55s 79ms/step - loss: 0.2065 - accuracy: 0.9298 - val_loss: 2.0378 - val_accuracy: 0.5682\n",
            "Epoch 90/90\n",
            "\n",
            "Epoch 00090: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "704/704 [==============================] - 50s 71ms/step - loss: 0.2056 - accuracy: 0.9276 - val_loss: 2.0409 - val_accuracy: 0.5688\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7efe5bcb9d90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gdz9JMERjMWP",
        "outputId": "f8b8ce6d-df67-4327-9198-56fca46492ee"
      },
      "source": [
        "# Evaluate model on training set\n",
        "\n",
        "loss, acc = model.evaluate(x_test, y_test)\n",
        "print('Test accuracy = {}'.format(acc))\n",
        "print('Test loss = {}'.format(loss))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 4s 14ms/step - loss: 2.1302 - accuracy: 0.5618\n",
            "Test accuracy = 0.5618000030517578\n",
            "Test loss = 2.130187511444092\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "RSsuvFe9jy_b"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}